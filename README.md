# A-Brief-Introduction-to-Double-Descent-when-Over-parameterized
介绍Belkin等人(2019, 2020)和Nakkiran等人(2019)关于双降现象的工作：在机器学习模型中，当参数空间的维数超过样本量(在统计学中称为高维)时，拟合的泛化误差先遵循传统的U型曲线，然后又再次下降。我的介绍报告总结了这些工作中模拟的双下降曲线和在最简单假设下（线性回归，标准正态）关于曲线形状的数学推导。并自行模拟了简单线性回归下的双下降曲线，尽管它最初是在深度学习模型中被观察到的。

Introduce the work of Belkin et al.(2019, 2020) and Nakkiran et al.(2019) on the double descent phenomenon: In machine learning models, when the dimension of parameter space grows beyond population (called high-dimension in statistics), the fitted generalization error follows a traditional U-shaped curve first and then drops again. My introductory report summarizes the double descent curves simulated in these works and the mathematical derivation about the curve shape under the simplest assumptions (linear regression and standard normal). I also simulate the double descent curve of simple linear regression, although it was originally observed in a deep learning model.
